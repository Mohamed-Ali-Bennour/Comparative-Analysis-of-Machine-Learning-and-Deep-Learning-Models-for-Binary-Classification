{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Introduction:**\n",
        "\n",
        "In this analysis, we will test the performance of three deep learning models—ANN, CNN, and RNN—on a binary classification task. ANNs are flexible models that can capture complex patterns in data. CNNs, typically used for image data, will be applied to tabular data to see if they can identify feature interactions. RNNs are designed for sequential data and will be tested to check if they can handle any temporal or ordered relationships in the data. We aim to compare the effectiveness of each model for this task.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QZnqRnCIwyr2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Machine Learnig\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "lsouVbq7fggc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(\"/content/mushroom_cleaned.csv\")"
      ],
      "metadata": {
        "id": "S3zK2TSgfkL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.shape)\n",
        "train.head()\n",
        "X = train.drop('class', axis=1)\n",
        "y = train['class']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oauSno1fpyE",
        "outputId": "a2ff8589-8aa8-4511-9899-3f88cdb887bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(53595, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. ANN:**\n",
        "\n",
        "In this part, we will use an Artificial Neural Network (ANN) model to perform binary classification on the dataset. The ANN will be trained to predict the output based on 8 input features, and we will evaluate its performance using the accuracy metric.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ShRjf4oen_ak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(8, input_shape=(X_train.shape[1],), activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model for binary classification\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
        "print(f'Test accuracy: {test_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVyDW-Unh8ps",
        "outputId": "7d0f575f-5c33-4023-d2cd-f58e76bed9d3",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.5181 - loss: 10.5293 - val_accuracy: 0.6027 - val_loss: 0.6889\n",
            "Epoch 2/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.5784 - loss: 0.7283 - val_accuracy: 0.5892 - val_loss: 0.6635\n",
            "Epoch 3/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5704 - loss: 0.7141 - val_accuracy: 0.5472 - val_loss: 0.6786\n",
            "Epoch 4/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.5772 - loss: 0.7100 - val_accuracy: 0.6018 - val_loss: 0.6614\n",
            "Epoch 5/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5792 - loss: 0.6910 - val_accuracy: 0.6042 - val_loss: 0.7472\n",
            "Epoch 6/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5810 - loss: 0.6870 - val_accuracy: 0.5559 - val_loss: 0.6979\n",
            "Epoch 7/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5871 - loss: 0.6773 - val_accuracy: 0.5779 - val_loss: 0.6576\n",
            "Epoch 8/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5907 - loss: 0.6621 - val_accuracy: 0.5771 - val_loss: 0.6563\n",
            "Epoch 9/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6049 - loss: 0.6533 - val_accuracy: 0.6153 - val_loss: 0.6586\n",
            "Epoch 10/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6152 - loss: 0.6488 - val_accuracy: 0.6209 - val_loss: 0.6437\n",
            "Epoch 11/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6212 - loss: 0.6465 - val_accuracy: 0.6260 - val_loss: 0.6408\n",
            "Epoch 12/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6277 - loss: 0.6431 - val_accuracy: 0.6208 - val_loss: 0.6428\n",
            "Epoch 13/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.6335 - loss: 0.6360 - val_accuracy: 0.6205 - val_loss: 0.6609\n",
            "Epoch 14/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6387 - loss: 0.6371 - val_accuracy: 0.6402 - val_loss: 0.6293\n",
            "Epoch 15/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6283 - loss: 0.6358 - val_accuracy: 0.6215 - val_loss: 0.6396\n",
            "Epoch 16/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6356 - loss: 0.6328 - val_accuracy: 0.6428 - val_loss: 0.6250\n",
            "Epoch 17/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.6391 - loss: 0.6315 - val_accuracy: 0.6435 - val_loss: 0.6248\n",
            "Epoch 18/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.6378 - loss: 0.6328 - val_accuracy: 0.6295 - val_loss: 0.6361\n",
            "Epoch 19/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6404 - loss: 0.6308 - val_accuracy: 0.6357 - val_loss: 0.6299\n",
            "Epoch 20/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.6379 - loss: 0.6260 - val_accuracy: 0.6257 - val_loss: 0.6281\n",
            "Epoch 21/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.6443 - loss: 0.6255 - val_accuracy: 0.6467 - val_loss: 0.6219\n",
            "Epoch 22/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6442 - loss: 0.6255 - val_accuracy: 0.6432 - val_loss: 0.6247\n",
            "Epoch 23/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.6435 - loss: 0.6247 - val_accuracy: 0.6558 - val_loss: 0.6217\n",
            "Epoch 24/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6438 - loss: 0.6263 - val_accuracy: 0.6363 - val_loss: 0.6258\n",
            "Epoch 25/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6465 - loss: 0.6266 - val_accuracy: 0.6515 - val_loss: 0.6189\n",
            "Epoch 26/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6459 - loss: 0.6232 - val_accuracy: 0.6587 - val_loss: 0.6166\n",
            "Epoch 27/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.6476 - loss: 0.6214 - val_accuracy: 0.6505 - val_loss: 0.6183\n",
            "Epoch 28/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6556 - loss: 0.6174 - val_accuracy: 0.6375 - val_loss: 0.6304\n",
            "Epoch 29/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.6514 - loss: 0.6199 - val_accuracy: 0.6570 - val_loss: 0.6166\n",
            "Epoch 30/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6543 - loss: 0.6191 - val_accuracy: 0.6654 - val_loss: 0.6146\n",
            "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6681 - loss: 0.6196\n",
            "Test accuracy: 0.6653605699539185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. RNN:**\n",
        "\n",
        "\n",
        "In this part, we will implement and evaluate the performance of a Recurrent Neural Network (RNN) for binary classification. The model utilizes an LSTM layer with 16 units, which processes the input features as if they were sequential data.\n",
        "\n"
      ],
      "metadata": {
        "id": "pxEAVt7goQtM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train_rnn = X_train.values.reshape(X_train.shape[0], X_train.shape[1], 1)  # Adding 1 for single timestep\n",
        "X_test_rnn = X_test.values.reshape(X_test.shape[0], X_test.shape[1], 1)  # Adding 1 for single timestep\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.LSTM(16, input_shape=(X_train_rnn.shape[1], X_train_rnn.shape[2]), activation='relu', return_sequences=False),\n",
        "    tf.keras.layers.Dense(8, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train_rnn, y_train, epochs=30, batch_size=32, validation_data=(X_test_rnn, y_test))\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(X_test_rnn, y_test, verbose=1)\n",
        "print(f'Test accuracy: {test_accuracy:.2f}')\n",
        "\n"
      ],
      "metadata": {
        "id": "WuNkfwwboUHk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb06a8f8-0e05-4623-b054-f028ff02396f",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.6162 - loss: 0.8334 - val_accuracy: 0.6617 - val_loss: 0.6157\n",
            "Epoch 2/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.6804 - loss: 0.6009 - val_accuracy: 0.7211 - val_loss: 0.5395\n",
            "Epoch 3/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7508 - loss: 0.5011 - val_accuracy: 0.7865 - val_loss: 0.4463\n",
            "Epoch 4/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.7844 - loss: 0.4417 - val_accuracy: 0.8021 - val_loss: 0.4070\n",
            "Epoch 5/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8120 - loss: 0.3913 - val_accuracy: 0.8148 - val_loss: 0.3841\n",
            "Epoch 6/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.8279 - loss: 0.3616 - val_accuracy: 0.8523 - val_loss: 0.3239\n",
            "Epoch 7/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8502 - loss: 0.3297 - val_accuracy: 0.8693 - val_loss: 0.2978\n",
            "Epoch 8/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8582 - loss: 0.3178 - val_accuracy: 0.8711 - val_loss: 0.2851\n",
            "Epoch 9/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.8697 - loss: 0.2982 - val_accuracy: 0.8844 - val_loss: 0.2729\n",
            "Epoch 10/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8788 - loss: 0.2825 - val_accuracy: 0.8890 - val_loss: 0.2613\n",
            "Epoch 11/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.8832 - loss: 0.2786 - val_accuracy: 0.9061 - val_loss: 0.2294\n",
            "Epoch 12/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8925 - loss: 0.2534 - val_accuracy: 0.8900 - val_loss: 0.2542\n",
            "Epoch 13/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8968 - loss: 0.2473 - val_accuracy: 0.9133 - val_loss: 0.2246\n",
            "Epoch 14/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8962 - loss: 0.2526 - val_accuracy: 0.9052 - val_loss: 0.2397\n",
            "Epoch 15/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9072 - loss: 0.2309 - val_accuracy: 0.9170 - val_loss: 0.2125\n",
            "Epoch 16/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8792 - loss: 0.2844 - val_accuracy: 0.9129 - val_loss: 0.2082\n",
            "Epoch 17/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9069 - loss: 0.2399 - val_accuracy: 0.9289 - val_loss: 0.1776\n",
            "Epoch 18/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9225 - loss: 0.1974 - val_accuracy: 0.9284 - val_loss: 0.1925\n",
            "Epoch 19/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9285 - loss: 0.1856 - val_accuracy: 0.8741 - val_loss: 0.3111\n",
            "Epoch 20/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9199 - loss: 0.2100 - val_accuracy: 0.9226 - val_loss: 0.1904\n",
            "Epoch 21/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9319 - loss: 0.1789 - val_accuracy: 0.9442 - val_loss: 0.1467\n",
            "Epoch 22/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9379 - loss: 0.1624 - val_accuracy: 0.9312 - val_loss: 0.1803\n",
            "Epoch 23/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9385 - loss: 0.1638 - val_accuracy: 0.9329 - val_loss: 0.1632\n",
            "Epoch 24/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9393 - loss: 0.1589 - val_accuracy: 0.9463 - val_loss: 0.1425\n",
            "Epoch 25/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.9403 - loss: 0.1579 - val_accuracy: 0.9391 - val_loss: 0.1532\n",
            "Epoch 26/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9251 - loss: 0.1838 - val_accuracy: 0.8335 - val_loss: 0.3894\n",
            "Epoch 27/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8512 - loss: 0.3336 - val_accuracy: 0.9296 - val_loss: 0.1840\n",
            "Epoch 28/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9383 - loss: 0.1688 - val_accuracy: 0.9457 - val_loss: 0.1407\n",
            "Epoch 29/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9429 - loss: 0.1504 - val_accuracy: 0.9403 - val_loss: 0.1557\n",
            "Epoch 30/30\n",
            "\u001b[1m1340/1340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9453 - loss: 0.1511 - val_accuracy: 0.9171 - val_loss: 0.2128\n",
            "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2219\n",
            "Test accuracy: 0.92\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **CNN**:\n",
        "\n",
        "\n",
        "In this part of the analysis, we will apply a Convolutional Neural Network (CNN) to a binary classification task. While CNNs are typically used for image or sequential data, in this experiment, we will adapt them to tabular data by reshaping the input into a 3D format (samples, features, channels). The model consists of convolutional layers followed by pooling layers to reduce dimensionality, with dense layers at the end for binary classification."
      ],
      "metadata": {
        "id": "MNIXgu9Usx-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape the input data to 3D for CNN (batch_size, features, 1)\n",
        "X_train_cnn = X_train.values.reshape(X_train.shape[0], X_train.shape[1], 1)  # Reshaping to 3D\n",
        "X_test_cnn = X_test.values.reshape(X_test.shape[0], X_test.shape[1], 1)  # Reshaping to 3D\n",
        "\n",
        "# Build the CNN model for binary classification\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv1D(32, kernel_size=3, activation='relu', padding='same', input_shape=(X_train_cnn.shape[1], 1)),  # 1D convolutional layer with padding\n",
        "    tf.keras.layers.MaxPooling1D(pool_size=2),  # Max pooling layer to reduce dimensionality\n",
        "    tf.keras.layers.Conv1D(64, kernel_size=3, activation='relu', padding='same'),  # Second convolutional layer with padding\n",
        "    tf.keras.layers.MaxPooling1D(pool_size=2),  # Another max pooling layer\n",
        "    tf.keras.layers.Flatten(),  # Flatten the output to feed into the fully connected layers\n",
        "    tf.keras.layers.Dense(32, activation='relu'),  # Dense hidden layer\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer with sigmoid for binary classification\n",
        "])\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',  # Binary cross-entropy for binary classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train_cnn, y_train, epochs=50, batch_size=32, validation_data=(X_test_cnn, y_test))\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(X_test_cnn, y_test, verbose=1)\n",
        "print(f'Test accuracy: {test_accuracy:.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUJVaGxts2Gc",
        "outputId": "4ee16077-fda7-43fb-88b7-255cc6209ed4",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.5538 - loss: 1.9832 - val_accuracy: 0.6498 - val_loss: 0.6452\n",
            "Epoch 2/50\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5933 - loss: 0.8386 - val_accuracy: 0.6111 - val_loss: 0.7335\n",
            "Epoch 3/50\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6054 - loss: 0.7701 - val_accuracy: 0.6483 - val_loss: 0.6474\n",
            "Epoch 4/50\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6325 - loss: 0.6666 - val_accuracy: 0.6706 - val_loss: 0.6204\n",
            "Epoch 5/50\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6406 - loss: 0.6383 - val_accuracy: 0.6693 - val_loss: 0.5788\n",
            "Epoch 6/50\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6623 - loss: 0.5906 - val_accuracy: 0.6768 - val_loss: 0.5770\n",
            "Epoch 7/50\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6709 - loss: 0.5738 - val_accuracy: 0.7044 - val_loss: 0.5592\n",
            "Epoch 8/50\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.6858 - loss: 0.5613 - val_accuracy: 0.6757 - val_loss: 0.5802\n",
            "Epoch 9/50\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6953 - loss: 0.5446 - val_accuracy: 0.7252 - val_loss: 0.5145\n",
            "Epoch 10/50\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7179 - loss: 0.5098 - val_accuracy: 0.7357 - val_loss: 0.4947\n",
            "Epoch 11/50\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7264 - loss: 0.4964 - val_accuracy: 0.7379 - val_loss: 0.4798\n",
            "Epoch 12/50\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7332 - loss: 0.4805 - val_accuracy: 0.7512 - val_loss: 0.4545\n",
            "Epoch 13/50\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7627 - loss: 0.4413 - val_accuracy: 0.7790 - val_loss: 0.4209\n",
            "Epoch 14/50\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7733 - loss: 0.4310 - val_accuracy: 0.7775 - val_loss: 0.4258\n",
            "Epoch 15/50\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7905 - loss: 0.4058 - val_accuracy: 0.7725 - val_loss: 0.4330\n",
            "Epoch 16/50\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.7949 - loss: 0.3985 - val_accuracy: 0.8259 - val_loss: 0.3676\n",
            "Epoch 17/50\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8109 - loss: 0.3735 - val_accuracy: 0.8132 - val_loss: 0.3725\n",
            "Epoch 18/50\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8287 - loss: 0.3519 - val_accuracy: 0.8372 - val_loss: 0.3508\n",
            "Epoch 19/50\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8405 - loss: 0.3377 - val_accuracy: 0.8380 - val_loss: 0.3418\n",
            "Epoch 20/50\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8513 - loss: 0.3178 - val_accuracy: 0.8284 - val_loss: 0.3635\n",
            "Epoch 21/50\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8590 - loss: 0.3052 - val_accuracy: 0.8715 - val_loss: 0.2832\n",
            "Epoch 22/50\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8695 - loss: 0.2870 - val_accuracy: 0.8590 - val_loss: 0.3002\n",
            "Epoch 23/50\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8739 - loss: 0.2771 - val_accuracy: 0.8940 - val_loss: 0.2537\n",
            "Epoch 24/50\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8877 - loss: 0.2511 - val_accuracy: 0.8717 - val_loss: 0.2835\n",
            "Epoch 25/50\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8955 - loss: 0.2418 - val_accuracy: 0.8954 - val_loss: 0.2330\n",
            "Epoch 26/50\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8944 - loss: 0.2356 - val_accuracy: 0.9114 - val_loss: 0.2140\n",
            "Epoch 27/50\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9020 - loss: 0.2279 - val_accuracy: 0.8929 - val_loss: 0.2507\n",
            "Epoch 28/50\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9039 - loss: 0.2229 - val_accuracy: 0.9171 - val_loss: 0.1958\n",
            "Epoch 29/50\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9067 - loss: 0.2149 - val_accuracy: 0.9118 - val_loss: 0.2013\n",
            "Epoch 30/50\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9103 - loss: 0.2074 - val_accuracy: 0.9129 - val_loss: 0.1966\n",
            "Epoch 31/50\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9141 - loss: 0.2061 - val_accuracy: 0.9212 - val_loss: 0.1945\n",
            "Epoch 32/50\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9144 - loss: 0.2038 - val_accuracy: 0.9067 - val_loss: 0.2131\n",
            "Epoch 33/50\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9161 - loss: 0.1960 - val_accuracy: 0.9071 - val_loss: 0.2170\n",
            "Epoch 34/50\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9162 - loss: 0.1959 - val_accuracy: 0.9237 - val_loss: 0.1897\n",
            "Epoch 35/50\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9189 - loss: 0.1899 - val_accuracy: 0.9226 - val_loss: 0.1804\n",
            "Epoch 36/50\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9247 - loss: 0.1763 - val_accuracy: 0.9047 - val_loss: 0.2106\n",
            "Epoch 37/50\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9220 - loss: 0.1820 - val_accuracy: 0.9256 - val_loss: 0.1719\n",
            "Epoch 38/50\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9227 - loss: 0.1803 - val_accuracy: 0.8933 - val_loss: 0.2448\n",
            "Epoch 39/50\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9250 - loss: 0.1786 - val_accuracy: 0.9233 - val_loss: 0.1763\n",
            "Epoch 40/50\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9285 - loss: 0.1750 - val_accuracy: 0.9301 - val_loss: 0.1639\n",
            "Epoch 41/50\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9284 - loss: 0.1679 - val_accuracy: 0.9291 - val_loss: 0.1589\n",
            "Epoch 42/50\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9286 - loss: 0.1689 - val_accuracy: 0.9386 - val_loss: 0.1477\n",
            "Epoch 43/50\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9341 - loss: 0.1588 - val_accuracy: 0.8837 - val_loss: 0.2828\n",
            "Epoch 44/50\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9324 - loss: 0.1609 - val_accuracy: 0.9297 - val_loss: 0.1667\n",
            "Epoch 45/50\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9288 - loss: 0.1669 - val_accuracy: 0.9389 - val_loss: 0.1499\n",
            "Epoch 46/50\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9369 - loss: 0.1560 - val_accuracy: 0.9383 - val_loss: 0.1552\n",
            "Epoch 47/50\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9366 - loss: 0.1542 - val_accuracy: 0.9424 - val_loss: 0.1368\n",
            "Epoch 48/50\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9384 - loss: 0.1514 - val_accuracy: 0.9390 - val_loss: 0.1449\n",
            "Epoch 49/50\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9385 - loss: 0.1491 - val_accuracy: 0.9429 - val_loss: 0.1451\n",
            "Epoch 50/50\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9412 - loss: 0.1470 - val_accuracy: 0.9476 - val_loss: 0.1337\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9477 - loss: 0.1331\n",
            "Test accuracy: 0.95\n"
          ]
        }
      ]
    }
  ]
}